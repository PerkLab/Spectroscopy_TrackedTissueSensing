{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7ec0cde3",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5fee241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "# Import all of the requried libraries\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "# import statistics\n",
    "from statistics import mode,mean\n",
    "from scipy import interpolate\n",
    "import os\n",
    "import os.path\n",
    "import json\n",
    "import time\n",
    "\n",
    "# These are all of the libraries that I manually created\n",
    "\n",
    "import IOfunctions as IO\n",
    "import GUIfunctions as GUI\n",
    "import Processfunctions as process\n",
    "\n",
    "# Through 3D slicer\n",
    "# start_index = 0 # starts at 195nm\n",
    "# start_index = 742 # starts at 350nm\n",
    "start_index = 790 # starts at 360nm\n",
    "# start_index = 1070 # starts at 420nm\n",
    "\n",
    "# print pandas version\n",
    "print(pd.__version__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cff5d15b",
   "metadata": {},
   "source": [
    "## Data Loading and Formatting \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a8020e",
   "metadata": {},
   "source": [
    "#### Load, Format, and Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea877aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function combines loading the data with \n",
    "def loadDataset(dataPath,start_index=790,end_index=-1,sep=','):\n",
    "    '''\n",
    "    Function: loadDataset\n",
    "    ---------------------\n",
    "    This function loads in the data from the dataPath, records the time each sample was taken, and returns the dataset as a numpy array.\n",
    "    '''\n",
    "    Dataset = []\n",
    "    Time = []\n",
    "    print(\"Loading in: \", dataPath)\n",
    "    for name in os.listdir(dataPath):\n",
    "        # print(name)\n",
    "        df = pd.read_csv(os.path.join(dataPath,name), sep=sep,engine='python', header=None)\n",
    "        # trim to 360 nm\n",
    "        df = df.iloc[:, start_index:]\n",
    "        # convert to an array\n",
    "        data_arr = df.to_numpy()\n",
    "        # Sum the columns of the array\n",
    "#         spectrum_arr = np.sum(data_arr[1:, 1:],axis=0)\n",
    "        spectrum_arr = np.mean(data_arr[1:, 1:],axis=0)\n",
    "        # Grab the wavelength values\n",
    "        wavelength_arr = data_arr[0, 1:]\n",
    "        # Concatenate the vectors as columns\n",
    "        data_arr = np.concatenate((wavelength_arr.reshape(-1,1), spectrum_arr.reshape(-1,1)), axis=1)\n",
    "        # append to the dataset\n",
    "        Dataset.append(data_arr)\n",
    "\n",
    "        # Get the time of the sample\n",
    "        ctime = os.path.getctime(os.path.join(dataPath,name))\n",
    "        Time.append(ctime)\n",
    "    Dataset = np.array(Dataset,dtype='float')\n",
    "    Time = np.array(Time,dtype='float')\n",
    "    # print(\"Time shape: \", Time.shape)\n",
    "    return Dataset, Time\n",
    "\n",
    "# LOADING DATASET \n",
    "# FORMAT_DATASET = True\n",
    "FORMAT_DATASET = False\n",
    "dataset_name = 'KidneyData_march3'\n",
    "trialPath = \"C:/Users/David/OneDrive - Queen's University/1 Graduate Studies/1 Thesis Research/KidneyData_march3/March3_KidneyCollectionWithDrRen/Mar03\"\n",
    "sampleNameList = [f for f in os.listdir(trialPath) if f.startswith('Patient')]\n",
    "\n",
    "# define a pandas df to store the incoming data\n",
    "class0_name = 'Normal'\n",
    "class1_name = 'Cancer'\n",
    "\n",
    "if FORMAT_DATASET:\n",
    "    Formatted_dataset_df = pd.DataFrame(columns=['PatientID', 'SampleID', 'Label (numeric)', 'Label', 'Data', 'Time'])  \n",
    "    for sampleName in sampleNameList:\n",
    "        patientID = sampleName.split('_')[0]\n",
    "        sampleID = sampleName.split('_')[1] + '_' +sampleName.split('_')[2]\n",
    "        # define the class names for folders which start with cancer or normal\n",
    "        classNameList = [f for f in os.listdir(os.path.join(trialPath,sampleName)) if f.startswith('Cancer') or f.startswith('Normal')]\n",
    "        # Remove names containing AmbientLight\n",
    "        classNameList = [f for f in classNameList if not f.endswith('AmbientLight')]\n",
    "        # for each folder sampleName folder, check if the class folders exist\n",
    "        for className in classNameList:\n",
    "            # if className contains cancer, then label = 1\n",
    "            if class0_name in className:\n",
    "                label = 0\n",
    "            else:\n",
    "                label = 1\n",
    "            # Check to see if the path exists\n",
    "            dataPath = os.path.join(trialPath,sampleName,className)\n",
    "            if os.path.exists(dataPath):\n",
    "                data, time = loadDataset(dataPath,start_index=start_index, sep=',')\n",
    "                # for each data file, append to the dataset\n",
    "                for i in range(data.shape[0]):\n",
    "                    new_row = {'PatientID':patientID, \n",
    "                            'SampleID':sampleID, \n",
    "                            'Label (numeric)':label, \n",
    "                            'Label':className, \n",
    "                            'Data':data[i,:,:],\n",
    "                            'Time': time[i]\n",
    "                    }\n",
    "                    # Dataset_df = Dataset_df.append(new_row, ignore_index=True)\n",
    "                    Formatted_dataset_df = pd.concat([Formatted_dataset_df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "    # For each Data, convert the array to a string and save it to a csv file\n",
    "    Formatted_dataset_df['Data'] = Formatted_dataset_df['Data'].apply(lambda x: json.dumps(x.tolist()))\n",
    "    file_name = os.path.join(trialPath, dataset_name + '_Formatted_Dataset.csv')\n",
    "    Formatted_dataset_df.to_csv(file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e70cb37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1678218862.6972723\n",
      "The file was created at 14:54:22\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "filename = os.path.join(\"C:/Users/David/OneDrive - Queen's University/1 Graduate Studies/1 Thesis Research/KidneyData_march3/March3_KidneyCollectionWithDrRen/Mar03\",\"March3_DataCollection.xlsx\")\n",
    "\n",
    "# get the file creation time\n",
    "ctime = os.path.getctime(filename)\n",
    "print(ctime)\n",
    "\n",
    "# convert the creation time to a readable format\n",
    "ctime_str = time.strftime('%H:%M:%S', time.localtime(ctime))\n",
    "\n",
    "print(f'The file was created at {ctime_str}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0028d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1677883286.3621924\n",
      "The sample was taken at 17:41:26\n"
     ]
    }
   ],
   "source": [
    "# get the time of the sample\n",
    "sample_time = Dataset_df.iloc[0,5]\n",
    "print(float(sample_time))\n",
    "# convert the creation time to a readable format\n",
    "sample_time_str = time.strftime('%H:%M:%S', time.localtime(sample_time))\n",
    "\n",
    "print(f'The sample was taken at {sample_time_str}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103f86d9",
   "metadata": {},
   "source": [
    "### Load from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "264b7891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(399, 6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = os.path.join(trialPath, dataset_name + '_Formatted_Dataset.csv')\n",
    "# Load in the dataset\n",
    "Dataset_df = pd.read_csv(file_name)\n",
    "# For each Data, convert the string back to an array\n",
    "Dataset_df['Data'] = Dataset_df['Data'].apply(lambda x: np.array(json.loads(x)))\n",
    "Dataset_df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "70a800bc",
   "metadata": {},
   "source": [
    "## Visualization Trials"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "942371e9",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0946b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that I have everything compiled into a dataframe, I can now split the data\n",
    "\n",
    "# Split the whole dataste into data into two classes\n",
    "allNormal_df = Dataset_df[Dataset_df['Label (numeric)'] == 0]\n",
    "allCancer_df = Dataset_df[Dataset_df['Label (numeric)'] == 1]\n",
    "\n",
    "# Get just data which sampleID contains 1_front\n",
    "sample1Normal_df = allNormal_df[allNormal_df['SampleID'].str.contains('1')]\n",
    "sample1Cancer_df = allCancer_df[allCancer_df['SampleID'].str.contains('1')]\n",
    "\n",
    "data_0_df = allNormal_df\n",
    "data_1_df = allCancer_df\n",
    "\n",
    "# Extract the data from the dataframe\n",
    "data_0 = np.array(data_0_df['Data'].tolist())\n",
    "labels0 = np.array(data_0_df['Label (numeric)'].tolist())\n",
    "data_1 = np.array(data_1_df['Data'].tolist())\n",
    "labels1 = np.array(data_1_df['Label (numeric)'].tolist())\n",
    "\n",
    "# labels1 = data_1_df['Label']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2e7206",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Normal data shape: ',data_0.shape)\n",
    "print('Cancer data shape: ',data_1.shape)\n",
    "# print the labels shape\n",
    "print('Normal labels: ',labels0.shape)\n",
    "print('Cancer labels: ',labels1.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d0d0a9",
   "metadata": {},
   "source": [
    "#### Load in the broadband transfer function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5408bfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadSpectrum(path, col_name=None,start_index=774,end_index=-1,sep=';'):\n",
    "#     df = pd.read_csv(path + name,sep=';',engine='python')\n",
    "    df = pd.read_csv(path,sep=sep,engine='python')\n",
    "#     print(df)\n",
    "    if not(col_name == None):\n",
    "        df[col_name] = df.index\n",
    "    data = df[start_index:end_index]\n",
    "#     print(data)\n",
    "    data_arr = data.to_numpy()\n",
    "    data_arr = np.array(data_arr,dtype='float')\n",
    "    return data_arr\n",
    "\n",
    "# LOAD IN BASELINES\n",
    "\n",
    "dataPath = os.getcwd()\n",
    "folderName = 'March2022_raw_data'\n",
    "file_name = 'SLS201L_Spectrum_reformatted.csv'\n",
    "dataPath_BrOut = os.path.join(dataPath,\"data\",folderName,file_name)\n",
    "print(dataPath_BrOut)\n",
    "baseline_BrOut_raw = loadSpectrum(dataPath_BrOut, 'Wavelength', start_index=10, end_index=675, sep=',')\n",
    "# Interpolate such that the downloaded spectrum has the same values of the data\n",
    "x = baseline_BrOut_raw[:,0]\n",
    "y = baseline_BrOut_raw[:,1]\n",
    "f = interpolate.interp1d(x,y)\n",
    "xnew = data_0[0,:,0]\n",
    "ynew = f(xnew)\n",
    "baseline_BrOut = np.transpose(np.array([xnew,ynew]))\n",
    "print(baseline_BrOut.shape)\n",
    "print('Data shape', data_0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c537e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(data_0[0,:,0],data_0[0,:,1])\n",
    "# plt.plot(data_1[0,:,0],data_1[0,:,1])\n",
    "# data_0.shape\n",
    "# print(data_0[0,0,0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d7c74cf1",
   "metadata": {},
   "source": [
    "### Display the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23590877",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Displaying all of the spectra to visually inspect results\n",
    "\n",
    "# This should be in GUI with all the inputs as parameters\n",
    "wavelength_start = data_0[0,0,0]\n",
    "wavelength_end = data_0[0,-1,0]\n",
    "\n",
    "w = np.linspace(wavelength_start,wavelength_end,len(data_0[1]))\n",
    "# # # Display an example of data_0\n",
    "# GUI.plotSpectra(xdata=data_0[0,:,0],ydata=data_0[0,:,1],xlab='Wavelength(nm)',ylab='Reflected Intensity',\n",
    "#                 title='Unprocessed data_0 Spectrum')\n",
    "# # Display an example of data_1\n",
    "# GUI.plotSpectra(xdata=data_1[0,:,0], ydata=data_1[0,:,1],xlab='Wavelength(nm)',ylab='Reflected Intensity',\n",
    "#                 title='Unprocessed data_1 Spectrum' )\n",
    "# Display an example of broadband output\n",
    "GUI.plotSpectra(xdata=baseline_BrOut[:,0],ydata=baseline_BrOut[:,1],xlab=\"Wavelength[nm]\",\n",
    "            ylab='Incident Intensity',title='baseline_BrOut')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76c5d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot all the spectra\n",
    "def plotAll(data,title='', xtitle='', ytitle=''):\n",
    "    plt.figure()\n",
    "    for i in range(len(data)):\n",
    "        plt.plot(data[i,:,0],data[i,:,1])\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xtitle)\n",
    "    plt.ylabel(ytitle)\n",
    "\n",
    "\n",
    "def plotWColourMap(data, title, xlabel, ylabel, step=1):\n",
    "    \"\"\"\n",
    "    Plot all samples of class1 on a single figure using a colour map to denote chronological order.\n",
    "\n",
    "    Args:\n",
    "    - data (ndarray): a 3D array of shape (num_samples, num_wavelengths, 2) containing the spectral data\n",
    "    - title (str): the title of the plot\n",
    "    - xlabel (str): the label of the x-axis\n",
    "    - ylabel (str): the label of the y-axis\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "\n",
    "    # create the colour map\n",
    "    cmap = plt.get_cmap('viridis')\n",
    "\n",
    "    # plot the data with the colour map\n",
    "    plt.figure()\n",
    "    for i in range(len(data)-1):\n",
    "        # plot every third spectra\n",
    "        if i%step == 0:\n",
    "            plt.scatter(data[i,:,0], data[i,:,1], s=0.1, c=cmap(i/len(data)))\n",
    "\n",
    "    # add a color bar\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap)\n",
    "    sm.set_array([])\n",
    "    plt.colorbar(sm)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all samples of class0 on a single figure without using plotSpectra\n",
    "plotAll(data_0,'All normal Spectra','Wavelength[nm]','Reflected Intensity')\n",
    "\n",
    "# Plot all samples of class1 on a single figure without using plotSpectra\n",
    "plotAll(data_1,'All cancer Spectra','Wavelength[nm]','Reflected Intensity')\n",
    "\n",
    "# GUI.plotSpectra(xdata=data_1[0,:,0], ydata=data_1[0,:,1],xlab='Wavelength(nm)',ylab='Reflected Intensity',\n",
    "#                 title='Unprocessed data_1 Spectrum' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b468005c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT the location of the max point for each spectrum\n",
    "def plotMax(data, title, xlabel, ylabel):\n",
    "    \"\"\"\n",
    "    Plot the location of the max point for each spectrum.\n",
    "\n",
    "    Args:\n",
    "    - data (ndarray): a 3D array of shape (num_samples, num_wavelengths, 2) containing the spectral data\n",
    "    - title (str): the title of the plot\n",
    "    - xlabel (str): the label of the x-axis\n",
    "    - ylabel (str): the label of the y-axis\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "\n",
    "    # find the max point for each spectrum\n",
    "    max_points_indices = np.argmax(data[:,:,1], axis=1)\n",
    "    # Find the corresponding wavelength\n",
    "    max_points = data[:,max_points_indices,0]\n",
    "    # plot the max points\n",
    "    SampleNumber = range(len(data))\n",
    "    plt.figure()\n",
    "    plt.scatter(max_points[0],range(len(data)))\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    # change the range of the x-axis\n",
    "    plt.xlim(400, 1000)\n",
    "\n",
    "# concatinate the data_0 and data_1\n",
    "d = np.concatenate((data_0, data_1), axis=0)\n",
    "# Plot the location of the max point for each spectrum of class0\n",
    "plotMax(d, 'Max point for all spectra', 'Wavelength index', 'Spectrum number')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c039ac22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_0_save = data_0.copy()\n",
    "# data_1_save = data_1.copy()\n",
    "\n",
    "# data_0 = data_0_save.copy()\n",
    "# data_1 = data_1_save.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effa2ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporayily remove the peak caused by ambient light\n",
    "data_0_new = data_0.copy()\n",
    "data_1_new = data_1.copy()\n",
    "# Set the spectra to zero between 600 and 650 nm\n",
    "# This is to remove the background noise using no functions\n",
    "def removeAmbientLight(data):\n",
    "    start_index = 1110\n",
    "    width = 20\n",
    "    end_index = start_index + width\n",
    "    for i in range(len(data)):\n",
    "        data[i,start_index:end_index,1] = 0\n",
    "    return data\n",
    "\n",
    "data_0_new = removeAmbientLight(data_0_new)\n",
    "data_1_new = removeAmbientLight(data_1_new)\n",
    "\n",
    "# concatinate the data_0 and data_1\n",
    "d = np.concatenate((data_0_new, data_1_new), axis=0)\n",
    "# Plot the location of the max point for each spectrum of class0\n",
    "plotMax(d, 'Max point for all spectra with ambient peak removed', 'Wavelength index', 'Spectrum number')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ab875077",
   "metadata": {},
   "source": [
    "### Preprocessing of the data\n",
    "* Normalize so peak is 1\n",
    "* Crop to 360nm to 1024nm\n",
    "* Divide by the broadband output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da308e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "data_0_norm = data_0_new.copy()\n",
    "data_1_norm = data_1_new.copy()\n",
    "data_0_norm = process.normalize(data_0_norm)\n",
    "data_1_norm = process.normalize(data_1_norm)\n",
    "\n",
    "# Plot them again\n",
    "# Plot all samples of class0 on a single figure without using plotSpectra\n",
    "plt.figure()\n",
    "for i in range(len(data_0_norm)):\n",
    "    plt.scatter(data_0_norm[i,:,0] ,data_0_norm[i,:,1],s=0.1)\n",
    "plt.title('All normal Spectra (MinMax Normalized))')\n",
    "plt.xlabel('Wavelength[nm]')\n",
    "plt.ylabel('Reflected Intensity')\n",
    "\n",
    "# Plot all samples of class1 on a single figure without using plotSpectra\n",
    "plt.figure()\n",
    "for i in range(len(data_1_norm)):\n",
    "    plt.scatter(data_1_norm[i,:,0],data_1_norm[i,:,1],s=0.5)\n",
    "plt.title('All cancer Spectra (MinMax Normalized)')\n",
    "plt.xlabel('Wavelength[nm]')\n",
    "plt.ylabel('Reflected Intensity')\n",
    "\n",
    "# # plot one cancer and one normal spectrum on a scatter plot\n",
    "# plt.figure()\n",
    "# plt.scatter(data_0_norm[0,:,0],data_0_norm[0,:,1],s=0.5)\n",
    "# plt.scatter(data_1_norm[0,:,0],data_1_norm[0,:,1],s=0.5)\n",
    "# plt.title('One cancer and one normal spectrum [MinMax Normalized]')\n",
    "# plt.xlabel('Wavelength[nm]')\n",
    "# plt.ylabel('Reflected Intensity')\n",
    "# plt.legend(['Normal','Cancer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b670be60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot each spectra using a color map to show how the spectra change over time\n",
    "# # This is to see if there is any pattern in the spectra\n",
    "# # use scatter plot to show the data points\n",
    "\n",
    "# # create the colour map\n",
    "# cmap = plt.get_cmap('viridis')\n",
    "\n",
    "# # plot the data with the colour map\n",
    "# plt.figure()\n",
    "# for i in range(len(data_1_norm)-1):\n",
    "#     plt.scatter(data_1_norm[i,:,0],data_1_norm[i,:,1],s=0.1,c=cmap(i/len(data_1_norm)))\n",
    "\n",
    "# # add a color bar\n",
    "# sm = plt.cm.ScalarMappable(cmap=cmap)\n",
    "# sm.set_array([])\n",
    "# plt.colorbar(sm)\n",
    "\n",
    "# plt.title('All normal Spectra (MinMax Normalized)')\n",
    "# plt.xlabel('Wavelength[nm]')\n",
    "# plt.ylabel('Reflected Intensity')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e46916",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "FLAG_Baseline = True\n",
    "# Load in the baseline \n",
    "baseline = baseline_BrOut # --------------------------------- flag\n",
    "baseline = process.normalize(baseline)[:,1]\n",
    "\n",
    "data_0_norm = data_0_new[:,280:,:].copy()\n",
    "data_1_norm = data_1_new[:,280:,:].copy()\n",
    "baseline = baseline[280:].copy()\n",
    "tFunc = baseline\n",
    "\n",
    "def divTfuc(inputData,tFunc, flag):    \n",
    "    outputData = inputData.copy()\n",
    "    if FLAG_Baseline:\n",
    "        # For each spectra\n",
    "        for i in range (inputData[:,:,1].shape[0]):\n",
    "            data = inputData[i,:,1]\n",
    "            # Divide by the baseline transfer function\n",
    "            outputData[i,:,1] = data / tFunc \n",
    "    outputData = process.normalize(outputData)\n",
    "    return outputData\n",
    "# call the function\n",
    "data_0_norm_T = divTfuc(data_0_norm,tFunc, FLAG_Baseline)\n",
    "data_1_norm_T = divTfuc(data_1_norm,tFunc, FLAG_Baseline)\n",
    "# Display the arguemtns and output\n",
    "freq = data_0_norm[0,:,0]\n",
    "\n",
    "# Plot all samples of class0 on a single figure without using plotSpectra\n",
    "# assuming data_1_norm_T is the input data array\n",
    "plotWColourMap(data_0_norm_T, 'All Normal Spectra (Tfunc Norm)', 'Wavelength[nm]', 'Reflected Intensity', )\n",
    "\n",
    "# Plot all samples of class1 on a single figure using a colour map to denote chronilogical order\n",
    "# assuming data_1_norm_T is the input data array\n",
    "plotWColourMap(data_1_norm_T, 'All cancer Spectra (Tfunc Norm)', 'Wavelength[nm]', 'Reflected Intensity')\n",
    "\n",
    "\n",
    "# plot the average of the cancer spectra and the average of the normal spectra on a scatter plot\n",
    "plt.figure()\n",
    "plt.scatter(data_0_norm_T[:,:,0].mean(axis=0),data_0_norm_T[:,:,1].mean(axis=0),s=0.5)\n",
    "plt.scatter(data_1_norm_T[:,:,0].mean(axis=0),data_1_norm_T[:,:,1].mean(axis=0),s=0.5)\n",
    "plt.title('Average cancer and normal spectra [Divided by broad band]')\n",
    "plt.xlabel('Wavelength[nm]')\n",
    "plt.ylabel('Reflected Intensity')\n",
    "plt.legend(['Normal','Cancer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc29ad1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_0_norm = data_0_norm_T\n",
    "data_1_norm = data_1_norm_T\n",
    "\n",
    "# # Plots of the normalized spectra\n",
    "# GUI.plotSpectra(xdata=data_0_norm[0,:,0],ydata=data_0_norm[0,:,1],xlab='Wavelength(nm)',ylab='Reflected Intensity',\n",
    "#                 title='Normalized data_0 Spectrum' )\n",
    "# GUI.plotSpectra(xdata=data_1_norm[0,:,0],ydata=data_1_norm[0,:,1],xlab='Wavelength(nm)',ylab='Reflected Intensity',\n",
    "#                 title='Normalized data_1 Spectrum' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaba080a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels1\n",
    "# # reindex the labels\n",
    "# labels1 = labels1.reset_index(drop=True)\n",
    "# # get the index of cancer\n",
    "# # cancer_index = labels1[labels1['label'] == 1].index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e3c89f22",
   "metadata": {},
   "source": [
    "## Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d295aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset_df\n",
    "# Extract the data from the dataframe\n",
    "data = np.array(Dataset_df['Data'].tolist())\n",
    "#pritn the shape of the data\n",
    "print('Dimensions of the data: ',np.shape(data))\n",
    "# Normalize the data\n",
    "data = process.normalize(data)\n",
    "# Remove ambient light peak\n",
    "data = removeAmbientLight(data)[:,280:,:] # I need to ravamp this function to use the data to remove the ambient light\n",
    "# Divide by the baseline transfer function\n",
    "processed_data = divTfuc(data,tFunc, FLAG_Baseline)\n",
    "# Turn the processed data into a singe data column in a dataframe\n",
    "data_df = pd.DataFrame()\n",
    "for i in range(processed_data.shape[0]):\n",
    "    new_row = {'Data_preprocessed':processed_data[i,:,:]}\n",
    "    data_df = pd.concat([data_df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "# Add the data to the dataframe\n",
    "processedData_df = pd.concat([Dataset_df, data_df], axis=1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d13263c3",
   "metadata": {},
   "source": [
    "## Trials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe25e27",
   "metadata": {},
   "source": [
    "### PCA fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01156852",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "# Get the data from the dataframe\n",
    "data = np.array(processedData_df['Data_preprocessed'].tolist())[:,:,1]\n",
    "# Create the PCA object\n",
    "pca = PCA(n_components=3)\n",
    "# Fit the PCA object to the data\n",
    "pca.fit(data)\n",
    "# Transform the data\n",
    "data_pca = pca.fit_transform(data)\n",
    "# Create a dataframe with the PCA data\n",
    "data_pca_df = pd.DataFrame(data_pca, columns=['PCA1','PCA2','PCA3'])\n",
    "# Add the PCA data to the dataframe\n",
    "data_pca_df = pd.concat([processedData_df, data_pca_df], axis=1)\n",
    "# data_pca_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "474e9935",
   "metadata": {},
   "source": [
    "### PCA - Class separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e40e7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plotting parameters\n",
    "a = 5\n",
    "figsize = (a,a)\n",
    "fontLabel = 15\n",
    "fontTitle = int(fontLabel*1.25)\n",
    "# # All scatter plot color options: https://matplotlib.org/3.1.0/gallery/color/named_colors.html\n",
    "\n",
    "# # 2D PCA: Cancer vs Normal\n",
    "# labels = [0,1]\n",
    "# colours = ['g','tab:orange']\n",
    "# plt.figure(figsize=figsize)\n",
    "# for label, colour in zip(labels,colours):\n",
    "#     plt.scatter(data_pca_df[data_pca_df['Label (numeric)'] == label]['PCA1'],data_pca_df[data_pca_df['Label (numeric)'] == label]['PCA2'],c = colour,s=25)\n",
    "#     # plt.scatter(data_pca_df[data_pca_df['Label (numeric)'] == 1]['PCA1'],data_pca_df[data_pca_df['Label (numeric)'] == 1]['PCA2'],c = colour,s=25)\n",
    "# plt.title('2D PCA: Cancer vs Normal', fontsize=fontTitle)\n",
    "# plt.xlabel('PCA1', fontsize=fontLabel)\n",
    "# plt.ylabel('PCA2', fontsize=fontLabel)\n",
    "# plt.legend(['Normal','Cancer'], fontsize=fontLabel)\n",
    "\n",
    "# # 2D PCA: all classes in the dataset\n",
    "# # get the unique labels\n",
    "# labels = np.unique(data_pca_df['Label'])\n",
    "# colours = ['tab:orange','tab:red','tab:pink','tab:purple','g']\n",
    "# plt.figure(figsize=figsize)\n",
    "# for label, colour in zip(labels,colours):\n",
    "#     plt.scatter(data_pca_df[data_pca_df['Label'] == label]['PCA1'],data_pca_df[data_pca_df['Label'] == label]['PCA2'],c=colour,s=25)\n",
    "# plt.title('2D PCA: all classes in the dataset', fontsize=fontTitle)\n",
    "# plt.xlabel('PCA1', fontsize=fontLabel)\n",
    "# plt.ylabel('PCA2', fontsize=fontLabel)\n",
    "# plt.legend(labels, fontsize=fontLabel)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc3a6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "# figSize = (800,800)\n",
    "figSize = (400,400)\n",
    "# Create a 3D plot of cancer vs normal\n",
    "fig = px.scatter_3d(data_pca_df, x='PCA1', y='PCA2', z='PCA3',title='3D PCA: Cancer vs Normal', color='Label', opacity=0.8, color_discrete_sequence=['orange','blue','orange','orange','orange'])\n",
    "fig.update_traces(marker=dict(size=5))\n",
    "fig.update_layout(width=figSize[0], height=figSize[1],title_x=0.5, title_y=0.8,legend=dict(x=0.8, y=0.8))\n",
    "fig.show()\n",
    "# Create a 3D plot of all classes in the dataset\n",
    "# color_discrete_sequence=['yellow','blue','orange','pink','red']\n",
    "fig = px.scatter_3d(data_pca_df, x='PCA1', y='PCA2', z='PCA3',title='3D PCA: all classes in the dataset', color='Label', opacity=0.8, color_discrete_sequence=['yellow','blue','orange','pink','red'])\n",
    "fig.update_traces(marker=dict(size=5))\n",
    "fig.update_layout(width=figSize[0], height=figSize[1],title_x=0.5, title_y=0.8,legend=dict(x=0.8, y=0.8))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2a552a",
   "metadata": {},
   "source": [
    "### PCA: Sample separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e908b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "figSize = (800,800)\n",
    "# 3D PCA: Sample1 vs Sample2 vs Sample3\n",
    "fig = px.scatter_3d(data_pca_df, x='PCA1', y='PCA2', z='PCA3',title='3D PCA: Sample1 vs Sample2 vs Sample3', color='SampleID', opacity=0.8, color_discrete_sequence=['orange','orange','red','red','pink','pink'])\n",
    "fig.update_traces(marker=dict(size=5))\n",
    "fig.update_layout(width=figSize[0], height=figSize[1],title_x=0.5, title_y=0.8,legend=dict(x=0.8, y=0.8))\n",
    "fig.show()\n",
    "\n",
    "# 3D PCA: plot pf cancer vs normal for sample 1 and 3\n",
    "data_1_3_df = data_pca_df[data_pca_df['SampleID'].str.contains('Sample1|Sample3')]\n",
    "fig = px.scatter_3d(data_1_3_df, x='PCA1', y='PCA2', z='PCA3',title='3D PCA: plot pf cancer vs normal for sample 1 and 3', color='Label', opacity=0.8, color_discrete_sequence=['orange','blue','orange','orange','orange','orange'])\n",
    "fig.update_traces(marker=dict(size=5))\n",
    "fig.update_layout(width=figSize[0], height=figSize[1],title_x=0.5, title_y=0.8,legend=dict(x=0.8, y=0.8))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd86ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D PCA: plot pf cancer vs normal for sample 1 and 3\n",
    "# get the sample ID which contain Sample1 and Sample3\n",
    "data_1_3_df = data_pca_df[data_pca_df['SampleID'].str.contains('Sample1|Sample3')]\n",
    "# print size of data_1_3_df\n",
    "print('Size of data_1_3_df: ',data_1_3_df.shape)\n",
    "fig = px.scatter_3d(data_pca_df, x='PCA1', y='PCA2', z='PCA3',title='3D PCA: all classes in the dataset', color='Label', opacity=0.8, color_discrete_sequence=['yellow','blue','orange','pink','red'])\n",
    "fig.update_traces(marker=dict(size=5))\n",
    "\n",
    "fig.update_layout(width=figSize[0], height=figSize[1],title_x=0.5, title_y=0.8,legend=dict(x=0.8, y=0.8))\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "23ad19db",
   "metadata": {},
   "source": [
    "### PCA over time TODO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# line up the cancer samples based on how long they have been out of the freezer. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a8309658",
   "metadata": {},
   "source": [
    "### LDA fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac75cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proceed with LDA on the data\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# Get the data from the dataframe\n",
    "data = np.array(processedData_df['Data_preprocessed'].tolist())[:,:,1]\n",
    "# Get the labels from the dataframe\n",
    "labels = np.array(processedData_df['Label (numeric)'].tolist())\n",
    "\n",
    "# Create the LDA object\n",
    "lda = LinearDiscriminantAnalysis(n_components=1)\n",
    "# Fit the LDA object to the data and labels\n",
    "lda.fit(data, labels)\n",
    "# Transform the data\n",
    "data_lda = lda.transform(data)\n",
    "print(data_lda.shape)\n",
    "# Create a dataframe with the LDA data\n",
    "data_lda_df = pd.DataFrame(data_lda, columns=['LDA1'])\n",
    "# Add the LDA data to the dataframe\n",
    "data_lda_df = pd.concat([processedData_df, data_lda_df], axis=1)\n",
    "data_lda_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bca6c921",
   "metadata": {},
   "source": [
    "### LDA: Class separation - Invalid since it needs to actually be trained on something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1D LDA: Cancer vs Normal\n",
    "labels = [0,1]\n",
    "colours = ['g','tab:orange']\n",
    "plt.figure(figsize=[12,3])\n",
    "for label, colour in zip(labels,colours):\n",
    "    plt.scatter(data_lda_df[data_lda_df['Label (numeric)'] == label]['LDA1'],y = np.zeros_like(data_lda_df[data_lda_df['Label (numeric)'] == label]['LDA1']) + 0.,c = colour,s=25)\n",
    "plt.title('1D LDA fitting: Cancer vs Normal', fontsize=fontTitle)\n",
    "plt.xlabel('LDA', fontsize=fontLabel)\n",
    "plt.legend(['Normal','Cancer'], fontsize=fontLabel)\n",
    "\n",
    "# 1D LDA: All classes in the dataset\n",
    "# get the unique labels\n",
    "labels = np.unique(data_lda_df['Label'])\n",
    "colours = ['tab:orange','tab:red','tab:pink','tab:purple','g']\n",
    "plt.figure(figsize=[12,5])\n",
    "for label, colour in zip(labels,colours):\n",
    "    plt.scatter(data_lda_df[data_lda_df['Label'] == label]['LDA1'],y = np.zeros_like(data_lda_df[data_lda_df['Label'] == label]['LDA1']) + 0.,c = colour,s=25)\n",
    "plt.title('1D LDA fitting: all classes in the dataset', fontsize=fontTitle)\n",
    "plt.xlabel('LDA', fontsize=fontLabel)\n",
    "plt.legend(labels, fontsize=fontLabel)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "43733f8d",
   "metadata": {},
   "source": [
    "### LDA: Sample separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19448ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1D LDA: Sample1 vs Sample2 vs Sample3\n",
    "SeparationIdx = 0\n",
    "SeparationIncrement = 0.05\n",
    "labels = np.unique(data_lda_df['SampleID'])\n",
    "colours = ['tab:orange','tab:orange','tab:red','tab:red','tab:pink','tab:pink']\n",
    "fig = plt.figure(figsize=[12,5])\n",
    "ax = fig.add_subplot(111)\n",
    "for label, colour in zip(labels,colours):\n",
    "    x = data_lda_df[data_lda_df['SampleID'] == label]['LDA1']\n",
    "    y = data_lda_df[data_lda_df['SampleID'] == label]['Label (numeric)']\n",
    "    # Spread out the data for better visibility\n",
    "    y = np.where(y==0,y+SeparationIdx,y-SeparationIdx)\n",
    "    ax.scatter(x,y,c=colour,s=50)\n",
    "    SeparationIdx = SeparationIdx + SeparationIncrement\n",
    "ax.set_title('1D LDA: Sample1 vs Sample2 vs Sample3', fontsize=fontTitle)\n",
    "ax.set_xlabel('LDA1', fontsize=fontLabel)\n",
    "ax.set_ylabel('Label (numeric)', fontsize=fontLabel)\n",
    "ax.legend(labels, fontsize=fontLabel)\n",
    "\n",
    "# 1D LDA: Sample1 vs Sample2 vs Sample3\n",
    "SeparationIdx = 0\n",
    "labels = np.unique(data_lda_df['SampleID'])[1:] # remove the first label\n",
    "print(labels)\n",
    "colours = ['tab:orange','tab:orange','tab:red','tab:red','tab:pink','tab:pink'][1:] # remove the first label\n",
    "print(colours)\n",
    "fig = plt.figure(figsize=[12,5])\n",
    "ax = fig.add_subplot(111)\n",
    "for label, colour in zip(labels,colours):\n",
    "    print(label, colour)\n",
    "    x = data_lda_df[data_lda_df['SampleID'] == label]['LDA1']\n",
    "    y = data_lda_df[data_lda_df['SampleID'] == label]['Label (numeric)']\n",
    "    # if y is 0 add 0.1 else subtract 0.1\n",
    "    y = np.where(y==0,y+SeparationIdx,y-SeparationIdx)\n",
    "    ax.scatter(x,y,c=colour,s=50)\n",
    "    SeparationIdx = SeparationIdx + SeparationIncrement\n",
    "ax.set_title('1D LDA: Sample1 vs Sample2 vs Sample3', fontsize=fontTitle)\n",
    "ax.set_xlabel('LDA1', fontsize=fontLabel)\n",
    "ax.set_ylabel('Label (numeric)', fontsize=fontLabel)\n",
    "ax.legend(labels, fontsize=fontLabel)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6161ac39",
   "metadata": {},
   "source": [
    "### 3D LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879f9223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the data\n",
    "processedData_df_3D = processedData_df.copy()\n",
    "# Change half of the Label (numeric label) = 1 to Label 'cancer1' and the other half to 'cancer2'\n",
    "processedData_df_3D.loc[processedData_df_3D['Label (numeric)'] == 1, 'Label'] = np.where(np.random.rand(len(processedData_df_3D[processedData_df_3D['Label (numeric)'] == 1])) > 0.5, 'cancer1', 'cancer2')\n",
    "# Change the numerican label for cancer1 to 2 and cancer2 to 3\n",
    "processedData_df_3D.loc[processedData_df_3D['Label'] == 'cancer1', 'Label (numeric)'] = 2\n",
    "processedData_df_3D.loc[processedData_df_3D['Label'] == 'cancer2', 'Label (numeric)'] = 3\n",
    "\n",
    "# Change half of the Label (numeric label) = 0 to Label to 'normal1' and the other half to 'normal2'\n",
    "processedData_df_3D.loc[processedData_df_3D['Label (numeric)'] == 0, 'Label'] = np.where(np.random.rand(len(processedData_df_3D[processedData_df_3D['Label (numeric)'] == 0])) > 0.5, 'normal1', 'normal2')\n",
    "# Change the numerican label for normal1 to 0 and normal2 to 1\n",
    "processedData_df_3D.loc[processedData_df_3D['Label'] == 'normal1', 'Label (numeric)'] = 0\n",
    "processedData_df_3D.loc[processedData_df_3D['Label'] == 'normal2', 'Label (numeric)'] = 1\n",
    "# print the data\n",
    "processedData_df_3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994dc3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proceed with LDA on the data\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# Get the data from the dataframe\n",
    "data = np.array(processedData_df_3D['Data_preprocessed'].tolist())[:,:,1]\n",
    "# Get the labels from the dataframe\n",
    "labels = np.array(processedData_df_3D['Label (numeric)'].tolist())\n",
    "\n",
    "# Create the LDA object\n",
    "lda = LinearDiscriminantAnalysis(n_components=3)\n",
    "# Fit the LDA object to the data and labels\n",
    "lda.fit(data, labels)\n",
    "# Transform the data\n",
    "data_lda = lda.transform(data)\n",
    "print(data_lda.shape)\n",
    "# Create a dataframe with the LDA data\n",
    "data_lda_df = pd.DataFrame(data_lda, columns=['LDA1','LDA2','LDA3'])\n",
    "# Add the LDA data to the dataframe\n",
    "data_3Dlda_df = pd.concat([processedData_df_3D, data_lda_df], axis=1)\n",
    "data_3Dlda_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcc94f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D LDA: All classes in the dataset\n",
    "# get the unique labels\n",
    "labels = np.unique(data_3Dlda_df['Label'])\n",
    "print\n",
    "colours = ['tab:orange','tab:red','tab:pink','tab:purple','g']\n",
    "fig = plt.figure(figsize=[12,5])\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "for label, colour in zip(labels,colours):\n",
    "    ax.scatter(data_3Dlda_df[data_3Dlda_df['Label'] == label]['LDA1'],data_3Dlda_df[data_3Dlda_df['Label'] == label]['LDA2'],data_3Dlda_df[data_3Dlda_df['Label'] == label]['LDA3'],c = colour,s=25)\n",
    "ax.set_title('3D LDA: All classes in the dataset', fontsize=fontTitle)\n",
    "ax.set_xlabel('LDA1', fontsize=fontLabel)\n",
    "ax.set_ylabel('LDA2', fontsize=fontLabel)\n",
    "ax.set_zlabel('LDA3', fontsize=fontLabel)\n",
    "ax.legend(labels, fontsize=12)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5cb05318",
   "metadata": {},
   "source": [
    "### LDA classifier - leave 1 out\n",
    "\n",
    "Train - Sample 1 and 2\n",
    "Test - Sample 3\n",
    "\n",
    "Train Sample 2 and 3\n",
    "Test - Sample 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de67ae17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using LDA to classify the data\n",
    "# Trial 1 - Train on sample1 and sample2 and test on sample3\n",
    "# Get the data which contains Sample1 and Sample2 from the dataframe\n",
    "train_X = np.array(processedData_df[processedData_df['SampleID'].str.contains('Sample1') | processedData_df['SampleID'].str.contains('Sample2')]['Data_preprocessed'].tolist())[:,:,1]\n",
    "train_y = np.array(processedData_df[processedData_df['SampleID'].str.contains('Sample1') | processedData_df['SampleID'].str.contains('Sample2')]['Label (numeric)'].tolist())\n",
    "# Get the test data which contains Sample3 from the dataframe\n",
    "test_X = np.array(processedData_df[processedData_df['SampleID'].str.contains('Sample3')]['Data_preprocessed'].tolist())[:,:,1]\n",
    "test_y = np.array(processedData_df[processedData_df['SampleID'].str.contains('Sample3')]['Label (numeric)'].tolist())\n",
    "\n",
    "# print the shapes of the data\n",
    "print(train_X.shape)\n",
    "print(train_y.shape)\n",
    "print(test_X.shape)\n",
    "print(test_y.shape)\n",
    "\n",
    "# Create the LDA object\n",
    "lda = LinearDiscriminantAnalysis(n_components=1)\n",
    "# Fit the LDA object to the data and labels\n",
    "lda.fit_transform(train_X, train_y)\n",
    "# Transform the data\n",
    "test_X_lda = lda.transform(test_X)\n",
    "test_pred = lda.predict(test_X)\n",
    "print('Labels: ', test_y)\n",
    "print('Predictions', test_pred)\n",
    "\n",
    "# print test_pred\n",
    "print('Test accuracy: ', np.sum(test_pred == test_y)/len(test_y))\n",
    "\n",
    "# Create a confusion matrix as a visualisation of the results\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(test_y, test_pred)\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de079a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using LDA to classify the data\n",
    "# Trial 2 - Train on sample3 and sample2 and test on sample1\n",
    "# Get the data which contains Sample3 and Sample2 from the dataframe\n",
    "train_X = np.array(processedData_df[processedData_df['SampleID'].str.contains('Sample3') | processedData_df['SampleID'].str.contains('Sample2')]['Data_preprocessed'].tolist())[:,:,1]\n",
    "train_y = np.array(processedData_df[processedData_df['SampleID'].str.contains('Sample3') | processedData_df['SampleID'].str.contains('Sample2')]['Label (numeric)'].tolist())\n",
    "# Get the test data which contains Sample1 from the dataframe\n",
    "test_X = np.array(processedData_df[processedData_df['SampleID'].str.contains('Sample1')]['Data_preprocessed'].tolist())[:,:,1]\n",
    "test_y = np.array(processedData_df[processedData_df['SampleID'].str.contains('Sample1')]['Label (numeric)'].tolist())\n",
    "\n",
    "# print the shapes of the data\n",
    "print(train_X.shape)\n",
    "print(train_y.shape)\n",
    "print(test_X.shape)\n",
    "print(test_y.shape)\n",
    "\n",
    "# Create the LDA object\n",
    "lda = LinearDiscriminantAnalysis(n_components=1)\n",
    "# Fit the LDA object to the data and labels\n",
    "lda.fit_transform(train_X, train_y)\n",
    "# Transform the data\n",
    "test_X_lda = lda.transform(test_X)\n",
    "test_pred = lda.predict(test_X)\n",
    "print (test_pred)\n",
    "# print test_pred\n",
    "print('Test accuracy: ', np.sum(test_pred == test_y)/len(test_y))\n",
    "\n",
    "# Create a confusion matrix as a visualisation of the results\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(test_y, test_pred)\n",
    "print(cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "84d8cac4d95fdd2ab02498a6ec40a50cb9882041e67cb52e6d8bcfda00d28db9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
